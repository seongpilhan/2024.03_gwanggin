# ê´‘ì§„êµ¬ ë¹…ë°ì´í„° ê³µëª¨ì „ - ì™¸ì‹ì—… íì—…ë¥  ìš”ì¸ë¶„ì„

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Pandas](https://img.shields.io/badge/pandas-1.3+-green.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-1.5+-red.svg)

ê´‘ì§„êµ¬ ì™¸ì‹ì—… ì˜ˆë¹„ ì°½ì—…ìë¥¼ ìœ„í•œ íì—…ë¥  ìš”ì¸ ë¶„ì„ ë° ì˜ˆì¸¡ ëª¨ë¸

## ğŸ¯ Overview

ì´ í”„ë¡œì íŠ¸ëŠ” ì½”ë¡œë‚˜ ì´í›„ì—ë„ ê³„ì†ë˜ëŠ” ì™¸ì‹ì—… íì—… í˜„ìƒì— ëŒ€í•´ ê´‘ì§„êµ¬ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ìš”ì¸ì„ ë¶„ì„í•˜ê³ , ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

- **Target Area**: ì„œìš¸ì‹œ ê´‘ì§„êµ¬
- **Analysis Period**: 2019ë…„ ~ 2023ë…„ (5ë…„ê°„)
- **Best Model**: Random Forest
- **Performance**: RMSE 5.9395, MAE 4.0214

## ğŸ“„ Research Background

### Problem Statement

**"ìŒì‹ì  10ê°œ ì°½ì—… ë•Œ 8ê°œ ì´ìƒ íì—…...íì—…ë¥ , íƒ€ì—…ì¢…ë³´ë‹¤ ë†’ì•„"**

- ìŠ¤íƒ€ ì‹ë‹¹ë„ ì¤„íì—…...ë¹› ë°”ëœ 'ë¯¸ì‰ë¦° ë³„'
- "ì½”ë¡œë‚˜ ë•Œë³´ë‹¤ í˜ë“¤ì–´ìš”"...ìŒì‹ì  ì¤„ íì—…

ì½”ë¡œë‚˜ ì´í›„ì—ë„ ê³„ì†ë˜ëŠ” ì™¸ì‹ì—…ì˜ íì—… í˜„ìƒì„ ë¶„ì„í•˜ì—¬ ê´‘ì§„êµ¬ ìŒì‹ì  íì—…ë¥ ì— ëŒ€í•œ ìœ ì˜ë¯¸í•œ ìš”ì¸ì„ ë„ì¶œí•˜ê³ ì í•©ë‹ˆë‹¤.

### Research Objective

ê´‘ì§„êµ¬ ì™¸ì‹ì—… ì˜ˆë¹„ ì°½ì—…ìë¥¼ ìœ„í•œ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì›

## ğŸ”¬ Method

### Data Collection

**ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ ì„œë¹„ìŠ¤ ë°ì´í„° í™œìš©**

#### ì—…ì²´ ìë£Œ
- ì„œë¹„ìŠ¤ ì—…ì¢…ëª…
- ì£¼ì¤‘/ì£¼ë§ ë§¤ì¶œ ê¸ˆì•¡
- ì‹œê°„ëŒ€ë³„ ë§¤ì¶œê¸ˆì•¡
- ì—°ë ¹ëŒ€ë³„ ë§¤ì¶œê¸ˆì•¡

#### ìƒê¶Œ ìë£Œ
- ìœ ì‚¬ì—…ì¢… ì í¬ ìˆ˜
- ê°œì—…ë¥ /íì—…ë¥ 
- í”„ëœì°¨ì´ì¦ˆ ì í¬ìˆ˜

### Analysis Pipeline
```
Data Collection (2019-2023)
    â†“
Hierarchical Linear Models (HLM)
    â”œâ”€ Level 1: ì‹œê°„
    â”œâ”€ Level 2-1: ìŒì‹ì 
    â””â”€ Level 2-2: í–‰ì •ë™
    â†“
Feature Engineering (Lasso Regression)
    â†“
Model Training & Comparison
    â”œâ”€ Linear Regression
    â”œâ”€ Random Forest âœ“
    â””â”€ XGBoost
    â†“
Feature Importance Analysis
```

## ğŸ“Š Results

### Model Performance Comparison

| Model | RMSE | MAE | Status |
|-------|------|-----|--------|
| Linear Regression | 5.9658 | 4.1190 | âœ“ |
| **Random Forest** | **5.9395** | **4.0214** | â­ **Selected** |
| XGBoost | 5.9396 | 4.1144 | âœ“ |

**Random Forestê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„**

### Key Findings - Feature Importance

#### Top 3 ì¤‘ìš” ë³€ìˆ˜ (Random Forest ê¸°ì¤€)

1. **ê°œì—…ë¥  (0.30)**
   - ê°œì—…ì´ í™œë°œí•˜ë©´ ê²½ìŸì´ ë”ìš± ì¹˜ì—´í•´ì§ˆ ìˆ˜ ìˆìŒ
   - ê¸°ì¡´ ê°€ê²Œë“¤ì˜ ì‹œì¥ ì ìœ ìœ¨ ê²½ìŸ ì‹¬í™”

2. **21ì‹œ~24ì‹œ ì˜ì—…ë§¤ì¶œ (0.05)**
   - 24ì‹œê¹Œì§€ ì˜ì—…í•˜ëŠ” ì í¬ëŠ” ì•¼ê°„ ê³ ê°ì¸µ íƒ€ê²Ÿ ê°€ëŠ¥
   - ë§¤ì¶œ ì¦ëŒ€ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆì–´ íì—…ë¥  ê°ì†Œ

3. **ìœ ì‚¬ì—…ì¢… ì í¬ìˆ˜ (0.04)**
   - ìœ ì‚¬ì—…ì¢… ë°€ì§‘ ì§€ì—­ì—ì„œ ê²½ìŸ ì¹˜ì—´
   - ê°€ê²©/ì„œë¹„ìŠ¤ ê²½ìŸìœ¼ë¡œ ìˆ˜ìµì„± ê°ì†Œ
   - íì—… ê°€ëŠ¥ì„± ì¦ê°€

### HLM Analysis Results

#### ìŒì‹ì  ìˆ˜ì¤€ ë¶„ì„
```
Level 1: íì—…ë¥ ij = Î³00 + Î³01*Timeij + Î³0i + Î³1i*Timeij + eij

Random Effect:
- Ï„00 = 1.195 (2019ë…„ 1ë¶„ê¸° ì—…ì¢…ë³„ íì—…ë¥  ì°¨ì´ ì¡´ì¬)
- Ï„01 = 0.007 (ìŒì‹ì  ê°„ ì‹œê°„ì— ë”°ë¥¸ ì°¨ì´ ê±°ì˜ ì—†ìŒ)

Fixed Effect:
- Î³00 = 4.500 (ì ˆí¸)
- Î³01 = -0.046 (ì‹œê°„ íš¨ê³¼ - ìœ ì˜í•˜ì§€ ì•ŠìŒ)

ICC = 0.005
```

#### í–‰ì •ë™ ìˆ˜ì¤€ ë¶„ì„
```
Level 1: íì—…ë¥ ij = Î³00 + Î³01*Timeij + Î³0i + Î³1i*Timeij + eij

Random Effect:
- Ï„00 = 0.048 (í–‰ì •ë™ ê°„ ì°¨ì´ ë§¤ìš° ì‘ìŒ)
- Ï„01 = 0.003 (ì‹œê°„ íš¨ê³¼ ì°¨ì´ ê±°ì˜ ì—†ìŒ)

Fixed Effect:
- Î³00 = 4.441 (ì ˆí¸)
- Î³01 = -0.041 (ì‹œê°„ íš¨ê³¼ - ìœ ì˜í•˜ì§€ ì•ŠìŒ)

ICC = 0.019
```

**â†’ ICCê°€ ë§¤ìš° ë‚®ì•„(0.005, 0.019) ì¢…ë‹¨ì  íŠ¹ì„±ì„ ë°˜ì˜í•˜ì§€ ì•ŠëŠ” ë¶„ì„ ë°©ë²•ë„ ê°€ëŠ¥**

## ğŸš€ Getting Started

### Prerequisites
```bash
Python 3.8+
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
xgboost>=1.5.0
matplotlib>=3.4.0
seaborn>=0.11.0
```

### Installation
```bash
# Clone the repository
git clone https://github.com/yourusername/gwangjin-restaurant-closure.git
cd gwangjin-restaurant-closure

# Install dependencies
pip install -r requirements.txt
```

### Data Preparation

1. ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ ì„œë¹„ìŠ¤ì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
2. `data/raw/` ë””ë ‰í† ë¦¬ì— ì €ì¥
```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ ì í¬ìˆ˜_2019-2023.csv
â”‚   â”œâ”€â”€ ê°œíì—…ìˆ˜_2019-2023.csv
â”‚   â””â”€â”€ ë§¤ì¶œë°ì´í„°_2019-2023.csv
```

### Quick Start
```python
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso

# ë°ì´í„° ë¡œë“œ
df = pd.load_csv('data/processed/gwangjin_restaurant_data.csv')

# íŠ¹ì§• ì„ íƒ (Lasso)
X = df.drop(['íì—…ë¥ '], axis=1)
y = df['íì—…ë¥ ']

# í‘œì¤€í™”
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Lassoë¡œ íŠ¹ì§• ì„ íƒ
lasso = Lasso(alpha=0.359)
lasso.fit(X_scaled, y)

# ì¤‘ìš” íŠ¹ì§• ì¶”ì¶œ
important_features = X.columns[lasso.coef_ != 0]

# Random Forest í•™ìŠµ
rf = RandomForestRegressor(
    n_estimators=200,
    max_depth=5,
    min_samples_leaf=8,
    min_samples_split=8,
    random_state=2024
)

rf.fit(X_scaled[:, important_features], y)

# ì˜ˆì¸¡
predictions = rf.predict(X_test_scaled)
```

## ğŸ“ Repository Structure
```
gwangjin-restaurant-closure/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ ì í¬ìˆ˜_2019-2023.csv
â”‚   â”‚   â”œâ”€â”€ ê°œíì—…ìˆ˜_2019-2023.csv
â”‚   â”‚   â””â”€â”€ ë§¤ì¶œë°ì´í„°_2019-2023.csv
â”‚   â””â”€â”€ processed/                  # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py       # ë°ì´í„° ì •ì œ
â”‚   â”‚   â””â”€â”€ feature_engineering.py # íŠ¹ì§• ê³µí•™
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ hlm_analysis.py        # ìœ„ê³„ì  ì„ í˜• ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”‚   â”œâ”€â”€ random_forest.py       # Random Forest (ìµœì¢… ëª¨ë¸)
â”‚   â”‚   â””â”€â”€ xgboost_model.py
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_selection/
â”‚   â”‚   â””â”€â”€ lasso_selection.py     # Lasso íŠ¹ì§• ì„ íƒ
â”‚   â”‚
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ importance_plot.py      # ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_HLM_analysis.ipynb
â”‚   â”œâ”€â”€ 03_feature_selection.ipynb
â”‚   â””â”€â”€ 04_model_comparison.ipynb
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/                     # í•™ìŠµëœ ëª¨ë¸
â”‚   â””â”€â”€ figures/                    # ì‹œê°í™” ê²°ê³¼
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Technologies Used

### Statistical Analysis
- **Hierarchical Linear Models (HLM)** - ì¢…ë‹¨ ë°ì´í„° ë¶„ì„
- **ICC (Intraclass Correlation)** - ì§‘ë‹¨ ê°„ ìƒê´€ ë¶„ì„

### Machine Learning
- **Lasso Regression** - íŠ¹ì§• ì„ íƒ
- **Random Forest** - ìµœì¢… ì˜ˆì¸¡ ëª¨ë¸
- **XGBoost** - ëª¨ë¸ ë¹„êµ
- **Grid Search CV** - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

### Data Processing
- **Pandas** - ë°ì´í„° ì²˜ë¦¬
- **NumPy** - ìˆ˜ì¹˜ ì—°ì‚°
- **StandardScaler** - ë°ì´í„° í‘œì¤€í™”

### Visualization
- **Matplotlib** - ê¸°ë³¸ ì‹œê°í™”
- **Seaborn** - í†µê³„ ì‹œê°í™”

## ğŸ’¡ Key Insights

### 1. ê°œì—…ë¥  (Opening Rate)

**ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜ (ì¤‘ìš”ë„: 0.30)**

- ê°œì—…ì´ í™œë°œí•˜ë©´ ê²½ìŸì´ ë”ìš± ì¹˜ì—´í•´ì§
- ê¸°ì¡´ ê°€ê²Œë“¤ì˜ ì‹œì¥ ì ìœ ìœ¨ ê²½ìŸ â†’ ê°€ê²©/ë§ˆì¼€íŒ… ê²½ìŸ ì‹¬í™”
- íì—… ê°€ëŠ¥ì„± ì¦ê°€

**ì°½ì—…ì ê°€ì´ë“œ:**
- ê°œì—…ë¥ ì´ ë†’ì€ ì§€ì—­ì€ í”¼í•  ê²ƒ
- ì°¨ë³„í™”ëœ ê²½ìŸë ¥ í™•ë³´ í•„ìˆ˜

### 2. 21ì‹œ~24ì‹œ ì˜ì—…ë§¤ì¶œ

**ì•¼ê°„ ì˜ì—…ì˜ ì¤‘ìš”ì„± (ì¤‘ìš”ë„: 0.05)**

- ì•¼ê°„ ë…¸ë™ ì¸êµ¬ íƒ€ê²Ÿ ê°€ëŠ¥
- ëŠ¦ì€ ì‹œê°„ ì„œë¹„ìŠ¤ ìˆ˜ìš”ì¸µ í™•ë³´
- ë§¤ì¶œ ì¦ëŒ€ â†’ íì—…ë¥  ê°ì†Œ

**ì°½ì—…ì ê°€ì´ë“œ:**
- ì•¼ê°„ ì˜ì—… ê°€ëŠ¥í•œ ì—…ì¢… ê³ ë ¤
- ì£¼ë³€ ìœ ë™ ì¸êµ¬ íŒ¨í„´ ë¶„ì„

### 3. ìœ ì‚¬ì—…ì¢… ì í¬ìˆ˜

**ê²½ìŸ ê°•ë„ ì§€í‘œ (ì¤‘ìš”ë„: 0.04)**

- ìœ ì‚¬ì—…ì¢… ë°€ì§‘ â†’ ì¹˜ì—´í•œ ê²½ìŸ
- ê°€ê²©/ì„œë¹„ìŠ¤ ê²½ìŸ â†’ ìˆ˜ìµì„± ê°ì†Œ
- ê²½ìŸë ¥ ë° ìƒì¡´ ê°€ëŠ¥ì„± ê°ì†Œ

**ì°½ì—…ì ê°€ì´ë“œ:**
- ìœ ì‚¬ì—…ì¢…ì´ ì ì€ ì§€ì—­ ì„ íƒ
- ë˜ëŠ” í™•ì‹¤í•œ ì°¨ë³„í™” ì „ëµ ìˆ˜ë¦½

## ğŸ“ˆ Model Details

### Lasso Feature Selection
```python
ìµœì ì˜ alpha: 0.3593813663804626

# ì„ íƒëœ íŠ¹ì§•
ì„ íƒëœ íŠ¹ì„± Index(['ê°œì—…_ë¥ '], dtype='object')
```

### Random Forest Hyperparameters

**Grid Search ìµœì  íŒŒë¼ë¯¸í„°:**
```python
{
    'n_estimators': 200,
    'max_depth': 5,
    'min_samples_leaf': 8,
    'min_samples_split': 8
}
```

### XGBoost Feature Importance

**Top 5 ì¤‘ìš” ë³€ìˆ˜:**
1. ì‹œê°„ëŒ€_06~11_ë§¤ì¶œ_ê¸ˆì•¡
2. ì£¼ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜
3. ê°œì—…_ìœ¨
4. ì‹œê°„ëŒ€_ê±´ìˆ˜~17_ë§¤ì¶œ_ê±´ìˆ˜
5. ë‚¨ì„±_ë§¤ì¶œ_ê¸ˆì•¡

## ğŸš§ Limitations

### 1. ë°ì´í„° ë¶€ì •í™•ì„±

ë°ì´í„°ì˜ ë¶€ì •í™•ì„±ìœ¼ë¡œ ì¸í•´ ëª…í™•í•œ ë¶„ì„ê³¼ í•´ì„ì— ì–´ë ¤ì›€ì´ ì¡´ì¬í•©ë‹ˆë‹¤.

### 2. ë©”íƒ€ë°ì´í„° ë¶€ì¬

ê° ì»¬ëŸ¼ì˜ í˜•ì„± ê³¼ì •ì„ ì•Œ ìˆ˜ ì—†ì–´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í•´ì„í•˜ëŠ” ê²ƒì— í•œê³„ì ì´ ì¡´ì¬í•©ë‹ˆë‹¤.

## ğŸ“ Use Cases

### ì˜ˆë¹„ ì°½ì—…ìë¥¼ ìœ„í•œ í™œìš© ë°©ì•ˆ

1. **ì…ì§€ ì„ ì •**
   - ê°œì—…ë¥ ì´ ë‚®ì€ ì§€ì—­ ìš°ì„  ê³ ë ¤
   - ìœ ì‚¬ì—…ì¢… ë°€ì§‘ë„ í™•ì¸

2. **ì˜ì—… ì „ëµ**
   - ì•¼ê°„ ì˜ì—… ê°€ëŠ¥ì„± ê²€í† 
   - ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ íŒ¨í„´ ë¶„ì„

3. **ê²½ìŸ ë¶„ì„**
   - ì£¼ë³€ ìœ ì‚¬ì—…ì¢… ì í¬ìˆ˜ ì¡°ì‚¬
   - ì°¨ë³„í™” ì „ëµ ìˆ˜ë¦½

4. **ë¦¬ìŠ¤í¬ í‰ê°€**
   - í•´ë‹¹ ì§€ì—­/ì—…ì¢… íì—…ë¥  í™•ì¸
   - ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •

## ğŸ“š References

### ë°ì´í„° ì¶œì²˜
- [ì„œìš¸ì‹œ ìƒê¶Œë¶„ì„ ì„œë¹„ìŠ¤](https://golmok.seoul.go.kr/) - ì§€ì—­ë¶„ì„ ë°ì´í„° (2019-2023)
  - ì í¬ìˆ˜
  - ê°œíì—…ìˆ˜
  - ì¸êµ¬ìˆ˜
  - ì‹ ìƒê¸°ì—… ìƒì¡´ìœ¨

### ì–¸ë¡  ê¸°ì‚¬
- ì„œìš¸ê²½ì œ(2024), "ìŠ¤íƒ€ ì‹ë‹¹ë„ ì¤„íì—…â€¦ë¹› ë°”ëœ 'ë¯¸ì‰ë¦° ë³„'"
- ì¡°ì„ ê²½ì œ(2024), "ì‘ë…„ ë¬¸ë‹«ì€ ì‹ë‹¹, ì½”ë¡œë‚˜ ë•Œë³´ë‹¤ ë§ì•˜ë‹¤"
- KBSë‰´ìŠ¤(2024), "ì½”ë¡œë‚˜ ë•Œë³´ë‹¤ í˜ë“¤ì–´ìš”"â€¦ìŒì‹ì  ì¤„ íì—…

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

â­ **Key Findings**: Random Forest ëª¨ë¸ì„ í†µí•´ ê°œì—…ë¥ , ì•¼ê°„ ì˜ì—…ë§¤ì¶œ, ìœ ì‚¬ì—…ì¢… ì í¬ìˆ˜ê°€ ê´‘ì§„êµ¬ ì™¸ì‹ì—… íì—…ë¥ ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ì„ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ì˜ˆë¹„ ì°½ì—…ìì˜ ì…ì§€ ì„ ì • ë° ê²½ì˜ ì „ëµ ìˆ˜ë¦½ì— ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
